---
layout: post
title: "02. Predict Houses Prices Dataset"
subtitle: "Predict Houses Prices Dataset"
categories: tutorial
tag: DA
comments: true
---
# 02. Predict Houses Prices Dataset

![Houses Prices](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B2.%20Regression%20Problem-Houses%20Prices%5D/imgs/00.houses%20prices.jpg)

### Step 4. Predict Houses Prices Dataset

데이터 전처리를 마쳤으니 pytorch 모델을 구성하고, 프로젝트 목표를 달성합시다.

합쳐서 전처리한 데이터를 training set과 validation set, test set으로 나눕니다.

```python
train = combine[:ntrain].values
test = combine[ntrain:].values
X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.1)
```

다음으로 딥 러닝 라이브러리 pytorch를 사용해 모델을 설계합니다. `torch.manual_seed(0)`은 코드 실행이 항상 같은 결과를 만들게 합니다. pytorch 모델을 만드는 방법은 이전에 설명했으니 생략하겠습니다.

```python
import torch
import torch.nn as nn
from torch.nn import functional as F
from torch.autograd import Variable

torch.manual_seed(0)

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(200, 216)
        self.fc2 = nn.Linear(216, 512)
        self.fc3 = nn.Linear(512, 216)
        self.fc4 = nn.Linear(216, 72)
        self.fc5 = nn.Linear(72, 18)
        self.fc6 = nn.Linear(18, 1)

        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):

        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = F.relu(self.fc4(x))
        x = F.relu(self.fc5(x))
        x = F.relu(self.fc6(x))

        return x
```

자, 모델을 만들었으니 만든 모델, 손실 함수와 optimizer를 선언합니다. 이번 모델에서 사용할 손실함수는 Mean Square Error입니다. MSE는 실측치와 예측치 사이의 오차를 제곱해 평균을 구하는 함수로, Regression model에서 가장 빈번하게 사용되는 손실함수입니다.

```python
model = Net()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
```

학습을 시작합니다. 유의해야 할 점은, 이전의 Crossentropy loss와 다르게 target과 output 모두 FloatTensor를 받는다는 것입니다.

```python
batch_size = 100
n_epochs = 1000
batch_no = len(X_train) // batch_size

val_loss_min = np.inf
for epoch in range(n_epochs):
    for i in range(batch_no):
        start = i * batch_size
        end = start + batch_size
        x_var = Variable(torch.FloatTensor(X_train[start:end]))
        y_var = Variable(torch.FloatTensor(y_train[start:end]).squeeze())

        optimizer.zero_grad()
        output = model(x_var)
        loss = torch.sqrt(criterion(torch.log(output.squeeze()), torch.log(y_var)))
        loss.backward()
        optimizer.step()

    if epoch % 1 == 0:
        X_val = Variable(torch.FloatTensor(X_val))
        y_val = Variable(torch.FloatTensor(y_val))
        val_output = model(X_val)
        val_loss = criterion(val_output, y_val.squeeze())

        if val_loss <= val_loss_min:
            print("Validation loss decreased ({:6f} ===> {:6f}). Saving the model...".format(val_loss_min, val_loss))
            torch.save(model.state_dict(), "../output/model.pt")
            val_loss_min = val_loss

        print('')
        print("Epoch: {} \tValidation Loss: {}".format(epoch+1, val_loss))

print('Training Ended! ')
```

학습 과정 중 가장 우수한 모델을 불러와 test data를 작성합니다.

pytorch의 모델을 불러오는 방식은 두 가지가 있습니다. 
1. 앞에서 모델 클래스를 선언한 뒤 모델 파라미터를 불러오는 방식
2. 모델의 형태와 모델 파라미터를 모두 불러오는 방식

일반적으로는 1번 방법이 주로 사용되지만, 2번 방법도 알아놓는 것이 좋습니다.

```python
model.load_state_dict(torch.load("../output/model.pt"))
```

이전에 target feature를 정규분포에 가깝게 만들 때, numpy의 log1p를 씌워주었습니다. 모델로 값을 예측하고, log1p의 역인 expm1을 씌워줍니다.

```python
test = Variable(torch.FloatTensor(test))
result = np.expm1(model(test).data.squeeze().numpy())
```

submission.csv를 저장, 제출합니다.

```python
submission = pd.DataFrame()
submission['Id'] = test_ID
submission['SalePrice'] = result
submission.to_csv('../output/submission.csv', index=False)
```

![Score](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B2.%20Regression%20Problem-Houses%20Prices%5D/imgs/02.Score.JPG)

이번 프로젝트에서도 개선할 부분이 많습니다. 제가 보여드린 score이상의 점수를 받는 데이터 분석을 해 보세요.
