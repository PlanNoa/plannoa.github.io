---
layout: post
title: "02. Preprocess + Predict MNIST Dataset"
subtitle: "Preprocess + Predict MNIST Dataset"
categories: tutorial
tag: DA
comments: true
---
## 02.Preprocess + Predict MNIST dataset

![Regression](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B3.%20Computer%20Vision-MNIST%2BEMNIST%5D/imgs/00.MNIST.jpg)

### Step 2. Preprocess MNIST Dataset

MNIST 데이터셋은 이전같은 eda를 생략하고 간단한 전처리 과정만 거칩니다. 이미 전처리가 완료된 데이터셋이기 때문입니다.

먼저 사용할 패키지들을 import 해줍니다.

pillow(PIL)은 파이썬에서 이미지를 다루는 라이브러리입니다.

```python
import pandas as pd
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from torchvision.utils import make_grid

import math

from PIL import Image
import numbers

import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')
```

이전 코드와 똑같이 output 폴더를 만들어주고, 데이터셋의 크기를 확인합니다.

```python
import os
if not os.path.exists('../output'):
    os.mkdir('../output')

train_df = pd.read_csv('../input_MNIST/train.csv')
test_df = pd.read_csv('../input_MNIST/test.csv')

n_train = len(train_df)
n_pixels = len(train_df.columns) - 1
n_class = len(set(train_df['label']))

print('Number of training samples: {0}'.format(n_train))
print('Number of training pixels: {0}'.format(n_pixels))
print('Number of classes: {0}'.format(n_class))
```

kaggle에서 제공하는 MNIST 데이터셋은 1d array형식이기 때문에 눈으로 확인하기 어렵습니다. 
몇 개의 데이터 샘플을 골라 확인해봅니다.

```python
random_sel = np.random.randint(n_train, size=8)

grid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].as_matrix()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)
plt.rcParams['figure.figsize'] = (16, 2)
plt.imshow(grid.numpy().transpose((1,2,0)))
plt.axis('off')
plt.show()
print(*list(train_df.iloc[random_sel, 0].values), sep = ', ')
```

![MNIST_pic](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B3.%20Computer%20Vision-MNIST%2BEMNIST%5D/imgs/02.MNIST_pic.jpg)

training set의 숫자 분포를 확인해봅니다. 만약 분포가 기울어져있다면 추가적인 가공을 할 필요가 있습니다.

```python
plt.rcParams['figure.figsize'] = (8, 5)
plt.bar(train_df['label'].value_counts().index, train_df['label'].value_counts())
plt.xticks(np.arange(n_class))
plt.xlabel('Class', fontsize=16)
plt.ylabel('Count', fontsize=16)
plt.grid('on', axis='y')
plt.show()
```

다행히 특별히 적거나 많은 데이터는 없는 것 같으니 그냥 넘어가도록 합니다.

![MNIST_class](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B3.%20Computer%20Vision-MNIST%2BEMNIST%5D/imgs/02.MNIST_class.jpg)

다음으로 DataLoader를 만듭니다. 지금까지는 데이터를 batch size에 따라 나누고 직접 모델에 넣었지만, DataLoader를 만들면 그런 작업을 할 필요가 없어집니다.

DataLoader는 Dataset, Transform, DataLoader 세 가지 부분으로 이루어집니다.
- Dataset: Dataset은 데이터를 담고 있는 array라고 생각하면 쉽습니다. init에 데이터를 읽어올 경로를, len에 데이터의 수를, getitem에 하나의 샘플을 return하는 코드를 넣어주면 됩니다.
- Transform: Transform은 데이터를 변환하는 부분입니다. 이번 MNIST dataset에는 데이터에 noise가 없지만, 만약 있다면 noise를 없애는 코드가 들어갑니다. 비슷하게 Data Augmentation을 해 줄수도 있습니다.
- DataLoader: DataLoader는 Dataset에서 데이터를 하나씩 가져오는 일을 합니다.

#### Dataset

밑의 코드를 보면 init함수에서 파일을 읽어오고 2d array로 변환해줍니다. getitem 함수에서 Transform을 사용해 Data Augmentation을 진행합니다.

```python
class MNIST_data(Dataset):
    def __init__(self, file_path,
                 transform=transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(),
                                               transforms.Normalize(mean=(0.5,), std=(0.5,))])
                 ):

        df = pd.read_csv(file_path)

        if len(df.columns) == n_pixels:
            # test data
            self.X = df.values.reshape((-1, 28, 28)).astype(np.uint8)[:, :, :, None]
            self.y = None
        else:
            # training data
            self.X = df.iloc[:, 1:].values.reshape((-1, 28, 28)).astype(np.uint8)[:, :, :, None]
            self.y = torch.from_numpy(df.iloc[:, 0].values)

        self.transform = transform

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        if self.y is not None:
            return self.transform(self.X[idx]), self.y[idx]
        else:
            return self.transform(self.X[idx])
```

#### Transform

Data Augmentation을 위해 RandomRotation, RandomShift를 만들어줍니다.
RandomRotation은 이미지를 입력한 각도 내에서 랜덤으로 회전시키고, 
RandomShift는 이미지를 입력한 픽셀 내에서 랜덤으로 밉니다.
이런 기본적인 Data Augmentation을 통해서도 모델의 성능을 향상시킬 수 있습니다.
Data Augmentaion에 관한 자세한 정보는 [이곳](https://nittaku.tistory.com/272)을 참고해주세요.

```python
class RandomRotation(object):
    def __init__(self, degrees, resample=False, expand=False, center=None):
        if isinstance(degrees, numbers.Number):
            if degrees < 0:
                raise ValueError("If degrees is a single number, it must be positive.")
            self.degrees = (-degrees, degrees)
        else:
            if len(degrees) != 2:
                raise ValueError("If degrees is a sequence, it must be of len 2.")
            self.degrees = degrees

        self.resample = resample
        self.expand = expand
        self.center = center

    @staticmethod
    def get_params(degrees):
        angle = np.random.uniform(degrees[0], degrees[1])
        return angle

    def __call__(self, img):
        def rotate(img, angle, resample=False, expand=False, center=None):
            return img.rotate(angle, resample, expand, center)

        angle = self.get_params(self.degrees)
        return rotate(img, angle, self.resample, self.expand, self.center)


class RandomShift(object):
    def __init__(self, shift):
        self.shift = shift

    @staticmethod
    def get_params(shift):
        hshift, vshift = np.random.uniform(-shift, shift, size=2)
        return hshift, vshift

    def __call__(self, img):
        hshift, vshift = self.get_params(self.shift)
        return img.transform(img.size, Image.AFFINE, (1, 0, hshift, 0, 1, vshift), resample=Image.BICUBIC, fill=1)
```

#### DataLoader

먼저 Dataset을 선언하고, pytorch의 DataLoader 함수로 Dataset을 감싸줍니다. 
Dataset에 Transform들을 넣어줄 때 있는 transforms.Compose는 그 안에 있는 transform들을 하나씩 실행해줍니다.
예를 들어 하나의 이미지가 변환될 때 
1. PIL 이미지 형식으로 변환
2. 20도의 범위 내에서 랜덤하게 회전
3. 3픽셀 안에서 랜덤하게 밀기
4. tensor 형식으로 바꾸기
5. 정규화하기

의 과정을 거칩니다.

DataLoader에 batch_size 인자를 넣어 한 번에 받을 데이터의 개수를 정할 수 있습니다.

```python
batch_size = 64

train_dataset = MNIST_data('../input_MNIST/train.csv', transform= transforms.Compose(
                            [transforms.ToPILImage(), RandomRotation(degrees=20), RandomShift(3),
                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))
test_dataset = MNIST_data('../input_MNIST/test.csv')


train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)
```

Transform이 기대대로 구현되었는지 확인해봅시다.

```python
rotate = RandomRotation(20)
shift = RandomShift(3)
composed = transforms.Compose([RandomRotation(20),
                               RandomShift(3)])

fig = plt.figure()
sample = transforms.ToPILImage()(train_df.iloc[65,1:].reshape((28,28)).astype(np.uint8)[:,:,None])
for i, tsfrm in enumerate([rotate, shift, composed]):
    transformed_sample = tsfrm(sample)

    ax = plt.subplot(1, 3, i + 1)
    plt.tight_layout()
    ax.set_title(type(tsfrm).__name__)
    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,28)), cmap='gray')

plt.show()
```

잘 적용된 것처럼 보입니다.

![MNIST_transform](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B3.%20Computer%20Vision-MNIST%2BEMNIST%5D/imgs/02.MNIST_transform.jpg)

### Step 3. Predict MNIST Dataset

DataLoader를 만들었으니 Net을 구성합니다. 

이전 titanic, houses prices 모델과 다른 점은 layer들이 두 부분으로 나뉘어 있으며, layer 초기화가 되어있다는 점입니다.

self.feature과 self.classification을 nn.Sequential로 묶은 것을 볼 수 있습니다. Sequential은 여러 layer들을 한 번의 호출로 사용할 수 있게 해 줍니다.

self.feature은 2d array형식의 데이터를 다루고(CNN), self.classifial은 이전 모델과 똑같이 1d array형식의 데이터를 다룹니다.

```python
class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
          
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
          
        self.classifier = nn.Sequential(
            nn.Dropout(p = 0.5),
            nn.Linear(64 * 7 * 7, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(p = 0.5),
            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(p = 0.5),
            nn.Linear(512, 10),
        )
          
        for m in self.features.children():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
        
        for m in self.classifier.children():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform(m.weight)
            elif isinstance(m, nn.BatchNorm1d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
                
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        
        return x  
```

모델을 선언하고 gpu환경(colab)을 사용할 경우를 대비해 `.cuda()`를 사용합니다. 
`torch.cuda.is_available()`를 사용하면 현재 개발환경에서 cuda를 사용할 수 있는지의 여부를 나타냅니다.

```python
model = Net()
optimizer = optim.Adam(model.parameters(), lr=0.003)
criterion = nn.CrossEntropyLoss()
exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

if torch.cuda.is_available():
    model = model.cuda()
    criterion = criterion.cuda()
```

이번에는 training 과정에 validation data를 사용하지 않고 매 epoch마다 모델을 저장합니다.

모델을 학습시키기 위해 train, 모델을 테스트하기 위해 evaluate 함수를 만듭니다.
train 함수는 한 epoch동안 train_loader에서 나온 데이터를 가지고 학습시키고, 
evaluate 함수는 인자로 받은 dataloader의 데이터를 가지고 예측합니다.

```python
def train(epoch):
    model.train()
    exp_lr_scheduler.step()

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = Variable(data), Variable(target)

        if torch.cuda.is_available():
            data = data.cuda()
            target = target.cuda()

        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        if (batch_idx + 1) % 100 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),
                       100. * (batch_idx + 1) / len(train_loader), loss.data))
    
    torch.save(model.state_dict(), "../output_MNIST/model.pt")


def evaluate(data_loader):
    model.eval()
    loss = 0
    correct = 0

    for data, target in data_loader:
        data, target = Variable(data, volatile=True), Variable(target)
        if torch.cuda.is_available():
            data = data.cuda()
            target = target.cuda()

        output = model(data)
        loss += F.cross_entropy(output, target, size_average=False).data
        pred = output.data.max(1, keepdim=True)[1]
        correct += pred.eq(target.data.view_as(pred)).cpu().sum()

    loss /= len(data_loader.dataset)

    print('\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\n'.format(
        loss, correct, len(data_loader.dataset),
        100. * correct / len(data_loader.dataset)))
```

작성한 함수들로 모델을 학습시키고 학습된 모델을 테스트합니다.

제 경우에는 총 50 epoch를 학습시키고 training data를 기준으로 96%의 정확도를 얻었습니다.

```python
n_epochs = 1

for epoch in range(n_epochs):
    train(epoch)
    evaluate(train_loader)
```

학습된 모델로 test dataset을 예측하기 위해 prediction 함수를 만듭니다.
evaluate 함수와 비슷한 모양입니다.

```python
def prediciton(data_loader):
    model.eval()
    test_pred = torch.LongTensor()
    
    for i, data in enumerate(data_loader):
        data = Variable(data, volatile=True)
        if torch.cuda.is_available():
            data = data.cuda()
            
        output = model(data)
        
        pred = output.cpu().data.max(1, keepdim=True)[1]
        test_pred = torch.cat((test_pred, pred), dim=0)
        
    return test_pred
```

이제 test dataset을 예측하고 제출할 예측 파일을 만듭니다.

```python
test_pred = prediciton(test_loader)
out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], 
                      columns=['ImageId', 'Label'])

print(out_df.head())

out_df.to_csv('../output_MNIST/submission.csv', index=False)
```

캐글에 제출하고 결과를 확인합니다.

![Score](https://github.com/PlanNoa/Deep-Learning-from-Scratch-for-newbie/raw/master/%5B3.%20Computer%20Vision-MNIST%2BEMNIST%5D/imgs/02.MNIST_score.jpg)

97.7%의 정확도를 얻었습니다. data augmentation 정도를 더 크게 한다면 더 높은 정확도를 얻을 수 있을 것 같습니다.